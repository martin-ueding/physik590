% Copyright © 2014 Martin Ueding <dev@martin-ueding.de>

\chapter{Methoden}

\section{Harmonischer Oszillator}

Der harmonische Oszillator ist ein elementares quantenmechanisches System, das
durch den Hamiltonoperator
\[
    \hat H = \frac{1}{2m} \hat p^2 + \frac{m}{2} \omega^2 \hat x^2
\]
bestimmt wird \parencite[(3.1)]{Schwabl/Quantenmechanik}. Die Energieeigenwerte
lassen sich durch Operatormethoden am elegantesten berechnen. Dazu führe ich
die dimensionslose Länge
\[
    \xi := \sqrt{\frac{m\omega}{\hbar}} x
\]
ein. Im Ortsraum ist $\hat p = - \iup \hbar \pd{}x$. Der dimensionslose Impuls
ist demnach $\hat \pi^2 = - \hbar\omega m \pd[2]{}\xi$. Somit kann der
Hamiltonoperator umgeschrieben werden zu:
\[
    \hat H = \frac{\hbar\omega}2 \del{\xi^2 - \dpd[2]{}\xi}.
\]

Mit den Leiteroperatoren
\[
    \hat a := \frac1{\sqrt2} \del{\hat \xi + \iup \hat \pi}
    \quad\text{und}\quad
    \hat a^\dagger := \frac1{\sqrt2} \del{\hat \xi - \iup \hat \pi}
\]
kann der Hamiltonoperator kompakt als
\[
    \hat H = \hbar\omega \sbr{\hat a^\dagger \hat a + \frac12}
\]
geschrieben werden \parencite[(3.8)]{Schwabl/Quantenmechanik}. Dabei habe ich
schon den Kommutator $[\hat a, \hat a^\dagger] = 1$ ausgenutzt. Der Operator
$\hat a^\dagger \hat a$ ist der Beseztungszahloperator $\hat n$. In der
Energieeigenbasis $\{ \ket n \}_{n \in \N_0}$ sind die Eigenwerte von $\hat n$
durch $n$ gegeben, so dass die Energieeigenwerte
\[
    E_n = \hbar\omega \sbr{n + \frac 12}
\]
gegeben sind.

Im Ortsraum sind die Lösungen der Schrödungergleichung gegeben durch
\parencite[(4.159)]{nolting-theo5}:
\[
    \psi_n(\xi) = \del{\frac{m\omega}{\hbar\piup}}^{\frac14} (n! 2^n)^{-\frac12}
    \exp\del{- \frac{\xi^2}2} H_n(\xi),
\]
wobei $H_n$ die Hermite-Polynome sind. Im Grundzustand ist die Wellenfunktion
also gegeben durch:
\[
    \psi_0(\xi) = \piup^{-\frac14} \exp\del{-
    \frac{\xi^2}2}.
\]
Die zugehörige Aufenthaltswahrscheinlichkeit ist
\[
    |\psi_0(\xi)|^2 = \frac1{\sqrt\piup} \exp(-x^2).
\]

Die Wellenfunktion und Aufenthaltswahrscheinlichkeit gilt nur für das
Kontinuum. Für ein Zeitgitter ergeben sich andere Werte, dazu mehr in
Abschnitt~\ref{sec:wellenfunktion_auf_gitter}.

% TODO Abschnitt mit Gitter.

\section{Pfadintegral}

Feynmans Pfadintegralformalismus erlaubt es ein quantenmechanisches System mit
$n$ Freiheitsgraden in ein klassisches System mit $n+1$ Freiheitsgraden zu
überführen \parencite[§12.4]{Thijssen/Computational_Physics}. Dieses System
kann dann mit Methoden ähnlich der statistischen Physik behandelt werden.
Analog zur kanonischen Zustandssumme tritt hier eine Summe über alle
Weltlinien, die zwischen festem Anfangs- und Endpunkt $x_\text A$ bzw. $x_\text
E$ und einem Zeitinterval $T$ liegen, auf
\parencite[(2.7)]{Creutz/Statistical_Approach_QM}:
\[
    Z(x_\text E, x_\text A) = \sum_{\text{Trajektorien $j$}} \exp\del{ \iup
    \frac{S_j}{\hbar}}.
\]

Die Phase mit der Wirkung $S$ wird stark variieren, so dass es ab dieser Stelle
hilfreich ist, imaginäre Zeit zu betrachten. Dazu wird $\tau := \iup t$
eingeführt, was man auch \emph{Wick-Rotation} nennt. Diese hat die Eigenschaft,
ein quantenmechanisches System in ein Thermodynamisches zu überführen
\parencite[24]{Stetz/AQT}.

Schreibt man $\int [\dif x]$ für eine Integration über alle
Trajektorien $x(\tau)$, die $x(0) = x_\text A$ und $x(T) = x_\text E$ erfüllen,
so kann die Summe umgeschrieben werden zu
\parencite[(2.1)]{Creutz/Statistical_Approach_QM}:
\[
    \int [\dif x] \, \exp\del{-\frac{S(x)}\hbar}.
\]
$S$ ist hier ein Funktional der Trajektorie $x$. Dieser Integrand wird nur in
der Nähe der minimalen Wirkung Beiträge liefern. Dies reduziert den Bereich des
Phasenraums, über den integriert werden muss, derart, dass die Integration mit
Monte Carlo Methoden gut möglich ist.

Die Wirkung ist auch hier die Zeitintegration der Lagrangefunktion
\parencite[(2.5)]{Creutz/Statistical_Approach_QM}:
\[
    S = \int_0^T \dif \tau \, \sbr{\frac 12 m \sbr{\dpd x\tau(\tau)}^2 + V(x)}
\]

Diskretisiert man die Weltlinien, so wird es möglich, die Integration über alle
Weltlinien auszuführen. Das Integrationsmaß wird bei einer Unterteilung in
$\timesites+1$ (also $0, \ldots, \timesites$) Zeitpunkte zu:
\[
    \int [\dif x]
    \quad\leadsto\quad
    \prod_{j = 1}^{\timesites-1} \int_{-\infty}^\infty \dif x_j.
\]
Der Abstand der diskreten Zeitpunkte ist der Einfachheit halber konstant und
wird als $\timestep$ definiert. Somit gilt $T = \timesites\timestep$. Durch die
Diskretisierung werden Weltlinien unterdrückt, die sich zwischen den
Zeitpunkten stark ändern. Im Gegensatz zur reellen Zeit, in der Weltlinien mit
beliebiger Wirkung in die Zustandssumme einfließen können, fließen mit
imaginärer Zeit Weltlinien mit großer Geschwindigkeit (und daher großer
Wirkung) exponentiell weniger stark ein. Daher ist die Benutzung eines
Zeitgitters in Kombination mit imaginärer Zeit legitim. Im Grenzfall $\timestep
\to 0$ erhält man den kontinuierlichen Fall zurück.

Durch die diskrete Zeit wird in der Wirkung die Zeitableitung durch einen
Differenzenquotient ersetzt. Die Lagrangefunktion hängt nur noch von zwei
aufeinanderfolgenden Koordinaten ab. Die Wirkung einer Weltlinie $\vec x_k$
wird dann gegeben durch
\parencite[(3.2)]{Creutz/Statistical_Approach_QM}:
\[
    S(\vec x_k) = \timestep \sum_{j = 1}^\timesites L\del{x_j^{(k)}, x_{j+1}^{(k)}},
\]
wobei periodische Randbedingungen mit $x_{\timesites} = x_0$ festgesetzt wurden.

\section{Integration über den Phasenraum}

Der Raum der möglichen diskreten Weltlinien hat $\timesites$ Dimensionen und
ist unendlich groß. Aufgrund der hohen Dimension sind Monte Carlo Methoden zu
bevorzugen. Der Bereich der Weltlinien, die einen nennenswerten Beitrag zum
Integral liefern, ist jedoch aufgrund der exponentiellen Gewichtung recht
klein. Der Algorithmus von Metropolis wählt die Weltlinien entsprechend dieser
Gewichtung so aus, dass ein ungewichteter Mittelwert dieser Weltlinien einen
Schätzwert für die gewünschte Größe gibt
\parencite[434]{Creutz/Statistical_Approach_QM}. Die Wahrscheinlichkeit, die
Trajektorie $\vec x_k$ zu erhalten, wird durch
\begin{equation}
    \label{eq:p_x_k}
    p(\vec x_k) = \frac{\exp(-S(\vec x_k))}{\int [\dif x] \, \exp(-S(\vec x))}
\end{equation}
gegeben \parencite[(3.6)]{Creutz/Statistical_Approach_QM}. Werden $\iterations$
Weltlinien durch den Metropolisalgorithmus generiert, so ist der Schätzwert
$\overline A$ für
eine Größe $\bracket A$
\parencite[(3.7)]{Creutz/Statistical_Approach_QM}:
\[
    \overline A := \frac1\iterations \sum_{k=1}^\iterations A(\vec x_k).
\]

\subsection{Markovketten}

Um die Weltlinien entsprechend gewichtet generieren zu können, kommt ein
bestimmter Markovprozess zum Einsatz, der aus einer Weltlinie die nächste
generiert. Für $\iterations \to \infty$ nähert sich die Verteilung der
Benötigten an. \parencite[434]{Creutz/Statistical_Approach_QM}

% Eigenschaften von Markovketten

Die Weltlinien des einen Oszillators, die aus den $\timesites$ Koordinaten
$\{x_j\}$ bestehen, können auch als Koordinaten für $\timesites$ Teilchen
interpretiert werden. Somit ist eine Trajektorie ein Zustand dieses
Vielteilchensystems. Man kann nun eine Übergangsmatrix $W_{ij}$ definieren, die
die Wahrscheinlichkeit angibt, dass das System vom Zustand $i$ in den Zustand
$j$ wechselt. Aufgrund der diskreten Zeit entspricht ein Zeitschritt einem
Übergangsschritt.

% FIXME Hier klarer machen, was die x indiziert und was ganze Trajektorien
% indiziert.

Die Matrixelemente müssen $W_{ij} \geq 0$, sowie muss $\sum_j W_{ij} = 1$
gelten, da jeder Zustand in einen nächsten (oder sich selbst) übergehen muss
\parencite[(3.8)]{Creutz/Statistical_Approach_QM}. Da die $x_j$ aus $\R$
stammen, muss die Übergangsmatrix eine Wahrscheinlichkeitsdichte sein. Die
analogen Bedingungen sind dann $W(x_i, x_j) \geq 0$ und $\int \dif x_j \,
W(x_i, x_j) = 1$ für alle $x_i$
\parencite[(3.9)]{Creutz/Statistical_Approach_QM}.

% Verkettung von Schritten
% Eigenvektor, Wahrscheinlichkeitsdichte
% Forderungen an W

Die Übergangswahrscheinlichkeit über einen Zwischenschritt wird durch
Integration über die Zwischenposition,
\[
    W^{(2)}(x_i, x_k) = \int \dif x_j \, W(x_i, x_j) W(x_j, x_k),
\]
ermittelt \parencite[(3.9)]{Creutz/Statistical_Approach_QM}. Daraus lässt die
Rekursionsformel
\[
    W^{(n)}(x_i, x_k) = \int \dif x_j \, W^{(n-1)}(x_i, x_j) W(x_j, x_k),
\]
konstruieren \parencite[(3.10)]{Creutz/Statistical_Approach_QM}. Aufgrund der
Eigenschaften von $W$ lässt sich zeigen\footnote{Siehe
    \parencite[435]{Creutz/Statistical_Approach_QM} und
\parencite[Anhang~B]{Creutz/Statistical_Approach_QM}.}, dass es eine
Zustandsverteilungsdichte $P$ gibt, so dass sie linker Eigenvektor von
$W^{(\infty)}$ ist. Das $W$, das für die Pfadintegrale benötigt wird, soll gerade
$p(x)$ aus \eqref{eq:p_x_k} als Eigenvektor haben. Somit sind die
Anforderungen an $W$ die folgenden \parencite[(3.18)]{Creutz/Statistical_Approach_QM}:
\begin{itemize}
    \item
        $W(x_i, x_j) > 0$ falls $p(x_i) > 0$ und $p(x_j) > 0$,
    \item
        $\int \dif x_j \, W(x_i, x_j) = 1$,
    \item
        $p(x_j) = \int \dif x_i \, p(x_i) W(x_i, x_j)$.
\end{itemize}

% Detailed Balance

Um die Bedingungen zu erfüllen, ist die Wahl von $W$ so, dass
\[
    \frac{W(x_i, x_j)}{W(x_j, x_i)} = \frac{p(x_j)}{p(x_i)}
\]
gilt, möglich \parencite[(3.23)]{Creutz/Statistical_Approach_QM}. In der Quelle
wird die Relation „detailed balance condition“ genannt. Dieses
\emph{detailiertes Gleichgewicht} sagt aus, dass es sich bei $p$ um einen
Gleichgewichtszustand handelt, da Anzahl der Übergänge von $x_i$ nach $x_j$
genauso groß sind wie in der Rückrichtung
\parencite[85]{Schwabl/Quantenmechanik_fuer_Fortgeschrittene}.

Im Algorithmus geht nicht die ganze Trajektorie $\vec x$ in einem Schritt auf
eine neue Trajektorie $\vec x'$ über. Vielmehr werden die $x_j$ einzeln in ein
$x_j'$ überführt. Nach $N$ dieser Einzelschritte ist eine neue Weltlinie $\vec
x'$ erzeugt. Einer dieser Einzelschritte führt die Weltlinie $\vec x$ in eine
Weltlinie $\tilde{\vec x}$ über. Dabei wird nur die Koordinate $x_j$ zu $x_j'$
geändert. Mit \eqref{eq:p_x_k} kann man daher die Beziehung
\parencite[(3.25)]{Creutz/Statistical_Approach_QM}
\[
    \frac{W(\vec x, \tilde{\vec x})}{W(\tilde{\vec x}, \vec x)}
    = \frac{\exp(-S(x_j'))}{\exp(-S(x_j))},
\]
herleiten, welche durch die Wahl $W(x_j, x_j') \propto \exp(-S(x_j'))$ zu
erfüllen ist \parencite[(3.27)]{Creutz/Statistical_Approach_QM}. Dieser
Algorithmus wird „heat bath algorithm“ bezeichnet und hat den Nachteil, dass
es schwer ist, $x_j'$ entsprechend der Verteilung $\exp(-S(x_j'))$ zu ziehen
\parencite[438]{Creutz/Statistical_Approach_QM}.

\subsection{Metropolis Algorithmus}

Der Algorithmus von Metropolis et al.\ umgeht dieses Problem, indem er nach
einer einfach zu implementierenden Vorschrift, die $x_j'$ generiert
\parencite[439]{Creutz/Statistical_Approach_QM}, siehe
Algorithmus~\ref{alg:metropolis}.

\begin{algorithm}
    \begin{algorithmic}
        \For{$j \gets 1, \ldots, \timesites$}
            \State $x_j' \gets$ \Call{Zufallzahl}{$-\infty$, $\infty$}
            \State $\Deltaup S \gets S(x_0, \ldots, x_{j-1}, x_j',
            x_{j+1}, \ldots, x_\timesites) - S(\{x_i\})$

            \If{$\Deltaup S \leq 0$}
                \State $x_j \gets x_j'$
            \Else
                \State $r \gets$ \Call{Zufallszahl}{0, 1}
                \If{$r < \exp(-\Deltaup S)$}
                    \State $x_j \gets x_j'$
                \EndIf
            \EndIf
        \EndFor
    \end{algorithmic}
    % XXX Die zweite Zeile der Unterschrift ist nicht eingerückt.
    \caption{%
        Metropolisalgorithmus. Die Funktion $\textsc{Zufallzahl}(a, b)$ erzeugt
        eine Zufallszahl im Interval $(a, b)$.
    }
    \label{alg:metropolis}
\end{algorithm}

Es werden also neue Werte für $x_j$, die $x_j'$, aus einer Verteilung gezogen.
Ist die Änderung der Wirkung $\Deltaup S$ negativ, so wird der neue Wert
übernommen. Andernfalls wird der Wert mit der Wahrscheinlichkeit
$\exp(-\Deltaup S)$ übernommen. Wenn der Abstand zwischen $x_j'$ und $x_j$ groß
ist, ist die Wahrscheinlichkeit, dass der Wert übernommen wird, sehr gering.
Daher ist es effizienter, $x_j'$ nicht aus dem Intervall $(-\infty, \infty)$ zu
ziehen, sondern eine Breite $\Delta$ einzuführen
\parencite[439]{Creutz/Statistical_Approach_QM}. Die Autoren schlagen eine
Einheitsverteilung im Bereich $[x_j - \margin, x_j + \margin]$ vor. Ich benutze
in meiner Implementierung eine Normalverteilung mit einer Standardabweichung
$\margin$. Dies führt zu noch höheren Akzeptanzraten für neue Werte, die die
Wirkung $S$ erhöhen. Um den Übergang zu einer neuen Konfiguration noch weiter
zu beschleunigen, kann man das Ziehen eines neuen $x_j'$ mehrfach für das
gleiche $j$ wiederholen. Dadurch ist es möglich, dass es sich stärker
verändert, als in einem einzigen Schritt. Die Anzahl dieser Wiederholungen
möchte ich mit $\rounds$ bezeichnen.

\citeauthor{Creutz/Statistical_Approach_QM} geben
\[
    W(x_j, x_j') = \frac1{N_0} \del{
        \Theta(-\Deltaup S) + \exp(- \Deltaup S) \Theta(\Deltaup S)
        + \int \dif x' \, \del{
            1 - \exp(-\Deltaup S)
        } \Theta(\Deltaup S) \delta(x_j' - x_j)
    }
\]
als Wahrscheinlichkeitsdichte für diesen Algorithmus an
\parencite[(3.28)]{Creutz/Statistical_Approach_QM}, wobei ich $\Deltaup S :=
S(x_j') - S(x_j)$ definiert habe, $\Theta$ die Heaviside Stufenfunktion und
$N_0$ das Volumen des Konfigurationsraumes ist. Mit dieser Gleichung kann
nachvollzogen werden, dass $W$ die geforderten Bedingungen erfüllt.

\section{Bootstrap Methode}

% TODO Bootstrap Methode beschreiben.

Der Fehler zu einem statistischen Schätzwert ist in der Regel nicht einfach
anzugeben. Für Größen wie den Mittelwert ist es unter Annahme einer
zugrundeliegenden Verteilung möglich, nicht jedoch für komplexere Größen. Eine
Möglichkeit, eine Fehlerabschätzung zu beliebigen Schätzwerten zu erhalten, ist
die \emph{Bootstrap Methode}. Bei dieser werden aus der gegebenen Probe neue
Proben erstellt und eine Metaanalyse durchgeführt.

Sei $X$ eine Zufallsgröße, $\bracket X$ der Erwartungs- und $\overline X$ der
Schätzwert. Aus einer Stichprobenmenge $\mathbb M$ kann nun die Zufallsgröße
berechnet werden: $\overline X = X(\mathbb M)$. Im Grenzwert erhält man den
Erwartungswert, also $\lim_{|\mathbb M| \to \infty} \overline X = \bracket X$.

Aus der wirklich erhobenen Stichprobenmenge erzeugt man nun $\bootstrapsamples$
weitere Mengen $\mathbb M_i$ durch Ziehen mit Zurücklegen. Für jede dieser
Mengen errechnet man die Zufallsgröße und erhält die Menge der Schätzwerte
\[
    \mathbb X = \{ X(\mathbb M_i) \colon 1 \leq i \leq N_\text P \}.
\]
% TODO Quellenangabe für „normalverteilt“.
Diese Schätzwerte sind annähernd normalverteilt. Somit ist der so errechnete
Erwartungswert $\overline X$ durch den Mittelwert von $\mathbb X$ gegeben. Der
Fehler $\Deltaup \overline X$ ist durch die Standardabweichung von $\mathbb X$
gegeben.

\section{GEVP-Methode}

Beim harmonischen Oszillator kann die Grundzustandsenergie über den Virialsatz
bestimmt werden.
% TODO Quellenangabe

% XXX Hier passt eigentlich das aus der Implementierung rein zu E_1 aus [CF80]
% rein.

Energien für noch höhere Zustände können mit dem „Generalized Eigenvalue
Problem“ (GEVP) errechnet werden.

\subsection{Interpolationsfelder}

Dazu werden Interpolationsfelder $O_i$ gewählt
\parencite[1]{Blossier/Eigenvalue}. In diesem Fall ist die Wahl $O_i(x) = x^i$
sinnvoll.
% TODO Quellenangabe / Danksagung

% TODO Erklärung, dass die Potenzen von x den Absteigeoperator enthalten und
% somit nur die gewünschten Zustände dabei herauskommen.
$x$ lässt sich durch die Ab- und Aufsteigeoperatoren $a$ bzw. $a^\dagger$
ausdrücken: $x \propto a + a^\dagger$
\parencite[(3.5a)]{Schwabl/Quantenmechanik}. Die Potenzen von $x$ enthalten
demnach Potenzen von $a$, womit die Matrixelemente $\braket{0|a^i|n} = 0$
sind, wenn $i < n$. Sie sind jedoch ebenfalls 0, wenn $i - n$ ungerade ist. Die größte
Potenz von $a$ in $x^i$ ist $a^i$. Bei einer geraden Anzahl an Auf- und
Absteigevorgängen kann es insgesamt keine ungerade Änderung der Quantenzahl $n$
geben. Daher tragen für ein Matrixelement mit einer geraden Potenz von $x$ auch
nur gerade Energieeigenzustände bei.

\subsection{Korrelationsfunktionen}

Mit den Interpolationsfeldern $O_i$ lassen sich die Korrelationsfunktionen
\[
    C_{ij}(t) := \Bracket{O_i(t) \, O_j^*(t)}
    = \Bracket{x^i(0) \, x^j(t)}
\]
definieren \parencite[(2.1)]{Blossier/Eigenvalue}.

Da $\bracket{x} = 0$ aufgrund der Symmetrie des Potentials zu erwarten ist,
werden die Mittelwerte über ungerade Größen, also mit $i + j$ ungerade,
annähernd verschwinden. Es ist daher nicht sinnvoll, diese Größen überhaupt zu
berechnen.

Um das System numerisch stabiler zu bekommen, wird die Korrelationsmatrix in
einen nur geraden und einen nur ungeraden Teil zerlegt, also beide $i$ und $j$
gerade bzw. ungerade. Da wie vorher beschrieben auch nur gerade bzw. ungerade
Energieeigenzustände beitragen, kann man so sogar gerade und ungerade Zustände
trennen.

Das generalisierte Eigenwertproblem, aus dessen Eigenwerte die Energien
extrahiert werde können, ist durch
\[
    \tens C(t) \, \vec v_n(t, t_0) = \lambda_n(t, t_0) \, \tens C(t_0) \, \vec v_n(t,
    t_0)
    \eqnsep
    n = 1, \ldots, N
    \eqnsep
    t > t_0
\]
gegeben \parencite[(2.1)]{Blossier/Eigenvalue}. Aus den Eigenwerten lassen sich
die effektiven Energien
\[
    E_n^\text{eff}(t, t_0) = - \partial_t \ln\del{\lambda_n(t, t_0)} \equiv -
    \frac 1\timestep \sbr{ \ln\del{\lambda_n(t+\timestep, t_0)} -
    \ln\del{\lambda_n(t, t_0)} }
\]
bestimmen \parencite[(2.4)]{Blossier/Eigenvalue}, die mit $t \to \infty$ gegen
die Energie $E_n$ konvergieren \parencite[(2.3)]{Blossier/Eigenvalue}.

\subsection{Lösung des GEVP durch Cholesky-Zerlegung}

Das generalisierte Eigenwertproblem $\tens A \vec v = \lambda \tens B \vec v$
kann durch Multiplikation mit $\tens B^{-1}$ von links in ein normales
Eigenwertproblem überführt werden, wobei jedoch Symmetrien von $\tens A$ und
$\tens B$ verloren gehen. Um dies zu vermeiden, kann man das Problem mit der
Cholesky-Zerlegung lösen. Diese zerlegt $\tens B$ in eine untere Dreiecksmatrix
$\tens L$, so dass $\tens B = \tens L \tens L^\dagger$ gilt. Vorraussetzung
ist, dass $\tens B$ positiv definit ist, was hier der Fall ist.
% TODO Warum ist die positiv definit?
\parencite{MacKinnon/GEVP}


Damit kann das Problem umgeformt werden zu \parencite[(3.31)]{MacKinnon/GEVP}
\[
    \sbr{\tens L^{-1} \tens A [\tens L^\dagger]^{-1}} \tens L^\dagger \vec x
    =
    \lambda [\tens L^\dagger \vec x].
\]
Definiert man nun
\[
    \tilde{\tens A} := \sbr{\tens L^{-1} \tens A [\tens L^\dagger]^{-1}}
    \eqnsep
    \tilde{\vec x} := \tens L^\dagger \vec x,
\]
lässt sich dies als normale Eigenwertproblem schreiben \parencite[(3.32)]{MacKinnon/GEVP}:
\[
    \tilde{\tens A} \tilde{\vec x} = \lambda \tilde{\vec x}.
\]

Für die Implementierung der Cholesky-Zerlegung benutze ich die Funktion
\texttt{Eigen::MatrixBase::llt()} \parencite{Eigen/LLT} aus der C++ Bibliothek
Eigen. Das normale Eigenwertproblem löse ich anschließend mit der Klasse
\texttt{Eigen::EigenSolver} \parencite{Eigen/EigenSolver}.


%\nocite{Thijssen/Computational_Physics}

%\nocite{Young/Jackknife}
%\nocite{Oser/Bootstrap}

%\nocite{Stroustrup/C++4}

% vim: ft=tex spell spelllang=de tw=79
